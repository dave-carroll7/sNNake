## sNNake: Evolutionary Algorithms at Play

![sNNek](https://github.com/jackdavidweber/cs152-project/blob/main/snake_training.gif?raw=true)

### Contributors:
- Jack Weber
- Dave Carroll
- David D'Attile

### Introduction Outline:
- **Introductory Paragraph:** For our project, we will use the videogame Snake in order to gain a better understanding of reinforcement learning, genetic algorithms, and collaboration.

- **Background Paragraph:** Reinforcement learning is commonly used in order to train agents to "play" games. This has been done in applications ranging from Chess (Deep Blue), to Go (AlphaGo), to even Snake.

- **Transition paragraph:** Our project attempts to take the simple trained Snake-playing agent a step forward by introducing different algorithms and game variations that will add complexity to the agent's behavior. We hope that these variations will provide insights into how organisms learn and evolve to compete and collaborate.

- **Details Paragraph:** Our projectâ€™s largest hurdle will be deciding the correct information and rewards to provide to the agent in order to maximize what we consider as the optimal outcome. We plan to base our project off of and expand the capabilities of an existing, open-source Snake game library written in Python.

- **Assessment Paragraph:** 
In this section, we will analyze how long it took for the agent to learn how to play Snake under various conditions. The conditions are as follows: (1) reinforcement algorithm playing Snake, (2) reinforcement algorithm evolved using genetic algorithms playing Snake, and (3) agents are forced to collaborate playing multiplayer Snake.

- **Ethics Paragraph:** Reinforcement algorithms similar to the algorithms we used in training our agent to play Snake utilize rewards mechanisms to drive their behavior. Humans define these rewards, which can often lead to potentially unexpected outcomes when we don't truly consider the ramifications of these definitions.
